{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d261ee64-eb3f-4ce2-b756-7266936d62b3",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>News Category Classification</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff3bbb-afd1-4723-855f-62be295a58dd",
   "metadata": {},
   "source": [
    "Here we are going to use compare BOW, BiGram and TriGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13d0cabc-9398-4c53-bf62-29f2c801dc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12695, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Watching Schrödinger's Cat Die University of C...</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WATCH: Freaky Vortex Opens Up In Flooded Lake</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entrepreneurs Today Don't Need a Big Budget to...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>These Roads Could Recharge Your Electric Car A...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Civilian 'Guard' Fires Gun While 'Protecting' ...</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category\n",
       "0  Watching Schrödinger's Cat Die University of C...   SCIENCE\n",
       "1     WATCH: Freaky Vortex Opens Up In Flooded Lake    SCIENCE\n",
       "2  Entrepreneurs Today Don't Need a Big Budget to...  BUSINESS\n",
       "3  These Roads Could Recharge Your Electric Car A...  BUSINESS\n",
       "4  Civilian 'Guard' Fires Gun While 'Protecting' ...     CRIME"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"news_dataset.json\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9ec794e-e393-47a2-a983-4746d133fb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "BUSINESS    4254\n",
       "SPORTS      4167\n",
       "CRIME       2893\n",
       "SCIENCE     1381\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "175d6bf2-63f1-42a2-83c3-8907aa28b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples = 1381\n",
    "\n",
    "df_business = df[df.category == 'BUSINESS'].sample(min_samples, random_state=2022)\n",
    "df_sports = df[df.category == 'SPORTS'].sample(min_samples, random_state=2022)\n",
    "df_crime = df[df.category == 'CRIME'].sample(min_samples, random_state=2022)\n",
    "df_science = df[df.category == 'SCIENCE'].sample(min_samples, random_state=2022)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "574f4063-a78a-4e3a-9b65-304ce15402ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "BUSINESS    1381\n",
       "SPORTS      1381\n",
       "CRIME       1381\n",
       "SCIENCE     1381\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = pd.concat([df_business, df_sports, df_crime, df_science])\n",
    "df_balanced.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8789df34-a95d-48dd-b29f-f3b24de429c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11967</th>\n",
       "      <td>GCC Business Leaders Remain Confident in the F...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>From the Other Side; an Honest Review from Emp...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>Mike McDerment, CEO of FreshBooks, Talks About...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>How to Market Your Business While Traveling th...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>How to Leverage Intuition in Decision-making I...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  category  \\\n",
       "11967  GCC Business Leaders Remain Confident in the F...  BUSINESS   \n",
       "2912   From the Other Side; an Honest Review from Emp...  BUSINESS   \n",
       "3408   Mike McDerment, CEO of FreshBooks, Talks About...  BUSINESS   \n",
       "502    How to Market Your Business While Traveling th...  BUSINESS   \n",
       "5279   How to Leverage Intuition in Decision-making I...  BUSINESS   \n",
       "\n",
       "       category_num  \n",
       "11967             0  \n",
       "2912              0  \n",
       "3408              0  \n",
       "502               0  \n",
       "5279              0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = {'BUSINESS': 0, 'SPORTS': 1, 'CRIME': 2, 'SCIENCE': 3}\n",
    "\n",
    "df_balanced['category_num'] = df_balanced['category'].map({\n",
    "    'BUSINESS': 0,\n",
    "    'SPORTS': 1, \n",
    "    'CRIME': 2, \n",
    "    'SCIENCE': 3\n",
    "})\n",
    "\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d3452bb-a838-4c7a-a445-323ca187ac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_balanced.text, \n",
    "    df_balanced.category_num, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2025,\n",
    "    stratify=df_balanced.category_num # It will create equal no of classes from each category\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb8dc6a3-8096-4445-851b-a2a0813ef816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4419,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2971     Hidden-Camera Video Reveals Chicken McNuggets'...\n",
       "11016    CBS Reporter Sparks Uproar By Mistakenly Claim...\n",
       "11460    15 Highest-Paying Companies In America Netflix...\n",
       "9690     Aroldis Chapman Never Gave The Apology He Shou...\n",
       "7164     Design in Startups from the Get-Go There has n...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d77d0d5-9fd7-4cbf-b35a-028f8e28e6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_num\n",
       "2    277\n",
       "3    276\n",
       "1    276\n",
       "0    276\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "219d4ffc-b872-4ce8-94c5-250718b5b6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85       276\n",
      "           1       0.91      0.87      0.89       276\n",
      "           2       0.87      0.88      0.88       277\n",
      "           3       0.90      0.80      0.85       276\n",
      "\n",
      "    accuracy                           0.87      1105\n",
      "   macro avg       0.87      0.87      0.87      1105\n",
      "weighted avg       0.87      0.87      0.87      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_bow', CountVectorizer(ngram_range = (1, 1))),        #using the ngram_range parameter \n",
    "     ('Multi NB', MultinomialNB())                                     #this is simple BOW\n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e91bca0-cf43-4aba-9340-f53bdcdd3e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.93      0.82       276\n",
      "           1       0.90      0.84      0.87       276\n",
      "           2       0.87      0.86      0.86       277\n",
      "           3       0.91      0.74      0.82       276\n",
      "\n",
      "    accuracy                           0.84      1105\n",
      "   macro avg       0.85      0.84      0.84      1105\n",
      "weighted avg       0.85      0.84      0.84      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_1_2_gram', CountVectorizer(ngram_range = (1, 2))),        #using the ngram_range parameter \n",
    "     ('Multi NB', MultinomialNB())                                         #Bag of N grams where n=2 i.e. Bigram\n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb3de859-e179-4c09-aa96-542faa18d740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.95      0.81       276\n",
      "           1       0.91      0.83      0.87       276\n",
      "           2       0.88      0.86      0.87       277\n",
      "           3       0.91      0.72      0.81       276\n",
      "\n",
      "    accuracy                           0.84      1105\n",
      "   macro avg       0.85      0.84      0.84      1105\n",
      "weighted avg       0.85      0.84      0.84      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_1_3_grams', CountVectorizer(ngram_range = (1, 3))),        #using the ngram_range parameter \n",
    "     ('Multi NB', MultinomialNB())                                          #Bag of N grams where n=3 i.e. Trigram\n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f933c31f-731c-4d86-98cb-eb4dc5b80d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8609     'Moby Dick' May Be More Than Just A Whale Of A...\n",
       "12429    Michelle Kwan Tweets Video Proving She's Still...\n",
       "3668     'Hano! A Century in the Bleachers' Profiles Sp...\n",
       "2461     Marcus Mariota Featured In Inspiring Beats By ...\n",
       "10054    The Most Brutal Photos From The Mayweather-McG...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d3e1455-5cba-4209-9a6e-b14d132971b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8609     3\n",
       "12429    1\n",
       "3668     1\n",
       "2461     1\n",
       "10054    1\n",
       "Name: category_num, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41814112-4da1-4051-b784-77a1b9f3247b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c971724-071d-47b8-af46-21a267cf821b",
   "metadata": {},
   "source": [
    "'BUSINESS': 0,\n",
    "    'SPORTS': 1, \n",
    "    'CRIME': 2, \n",
    "    'SCIENCE': 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e482657-6d75-4695-8204-5810710949f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.2.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.11.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rohit kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ede5a68-0fc3-4604-9ef4-1ae63df426f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Thor ate pizza\",\n",
    "    \"Loki is tall\",\n",
    "    \"Loki is eating pizza\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21268343-f8aa-4a8a-b758-60ab7f505d3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# load english language model and create nlp object from it\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(text):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# remove stop words and lemmatize the text\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     doc \u001b[38;5;241m=\u001b[39m nlp(text)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# load english language model and create nlp object from it\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "def preprocess(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    return \" \".join(filtered_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f475d2a-5e06-409f-ab4d-9b9d4b1b9f2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m corpus_processed \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     preprocess(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m corpus\n\u001b[0;32m      3\u001b[0m ]\n\u001b[0;32m      4\u001b[0m corpus_processed\n",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m corpus_processed \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mpreprocess\u001b[49m(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m corpus\n\u001b[0;32m      3\u001b[0m ]\n\u001b[0;32m      4\u001b[0m corpus_processed\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocess' is not defined"
     ]
    }
   ],
   "source": [
    "corpus_processed = [\n",
    "    preprocess(text) for text in corpus\n",
    "]\n",
    "corpus_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76330bbe-cd67-4481-a761-9d130a684530",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_balanced[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessed_txt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_balanced[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[43mpreprocess\u001b[49m) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocess' is not defined"
     ]
    }
   ],
   "source": [
    "df_balanced['preprocessed_txt'] = df_balanced['text'].apply(preprocess) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2a12b9-c743-4555-99b3-97cb7183177b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
